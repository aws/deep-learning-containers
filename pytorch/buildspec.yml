account_id: &ACCOUNT_ID <set-$ACCOUNT_ID-in-environment>
region: &REGION <set-$REGION-in-environment>
framework: &FRAMEWORK pytorch
version: &VERSION 1.11.0
short_version: &SHORT_VERSION "1.11"

repository_info:
  training_repository: &TRAINING_REPOSITORY
    image_type: &TRAINING_IMAGE_TYPE training
    root: !join [ *FRAMEWORK, "/", *TRAINING_IMAGE_TYPE ]
    repository_name: &REPOSITORY_NAME !join [pr, "-", *FRAMEWORK, "-", *TRAINING_IMAGE_TYPE]
    repository: &REPOSITORY !join [ *ACCOUNT_ID, .dkr.ecr., *REGION, .amazonaws.com/, *REPOSITORY_NAME ]
  inference_repository: &INFERENCE_REPOSITORY
    image_type: &INFERENCE_IMAGE_TYPE inference
    root: !join [ *FRAMEWORK, "/", *INFERENCE_IMAGE_TYPE ]
    repository_name: &REPOSITORY_NAME !join [pr, "-", *FRAMEWORK, "-", *INFERENCE_IMAGE_TYPE]
    repository: &REPOSITORY !join [ *ACCOUNT_ID, .dkr.ecr., *REGION, .amazonaws.com/, *REPOSITORY_NAME ]

context:
  training_context: &TRAINING_CONTEXT
    changehostname:
      source: docker/build_artifacts/changehostname.c
      target: changehostname.c
    start_with_right_hostname:
      source: docker/build_artifacts/start_with_right_hostname.sh
      target: start_with_right_hostname.sh
    example_mnist_file:
      source: docker/build_artifacts/mnist.py
      target: mnist.py
    deep_learning_container:
      source: ../../src/deep_learning_container.py
      target: deep_learning_container.py
  inference_context: &INFERENCE_CONTEXT
    torchserve-e3-entrypoint:
      source: docker/build_artifacts/torchserve-e3-entrypoint.py
      target: torchserve-e3-entrypoint.py
    torchserve-entrypoint:
      source: docker/build_artifacts/torchserve-entrypoint.py
      target: torchserve-entrypoint.py
    config:
      source: docker/build_artifacts/config.properties
      target: config.properties
    deep_learning_container:
      source: ../../src/deep_learning_container.py
      target: deep_learning_container.py

images:
  # BuildE3CPUPTTrainPy3DockerImage:
  #   <<: *TRAINING_REPOSITORY
  #   build: &PYTORCH_CPU_TRAINING_PY3 false
  #   enable_test_promotion: false
  #   image_size_baseline: 5000
  #   device_type: &DEVICE_TYPE cpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *OS_VERSION, "-e3" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /Dockerfile., *DEVICE_TYPE ]
  #   target: e3
  #   context:
  #     <<: *TRAINING_CONTEXT
  BuildE3GPUPTTrainPy3DockerImage:
    <<: *TRAINING_REPOSITORY
    build: &PYTORCH_GPU_TRAINING_PY3 false
    enable_test_promotion: false
    image_size_baseline: 14000
    device_type: &DEVICE_TYPE gpu
    python_version: &DOCKER_PYTHON_VERSION py3
    tag_python_version: &TAG_PYTHON_VERSION py38
    cuda_version: &CUDA_VERSION cu113
    os_version: &OS_VERSION ubuntu20.04
    tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *CUDA_VERSION, "-", *OS_VERSION, "-e3" ]
    docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /, *CUDA_VERSION, /Dockerfile.,
                         *DEVICE_TYPE ]
    target: e3
    context:
      <<: *TRAINING_CONTEXT
  # BuildSageMakerCPUPTTrainPy3DockerImage:
  #   <<: *TRAINING_REPOSITORY
  #   build: &PYTORCH_CPU_TRAINING_PY3 false
  #   image_size_baseline: 5000
  #   base_image_name: BuildE3CPUPTTrainPy3DockerImage
  #   device_type: &DEVICE_TYPE cpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *OS_VERSION, "-sagemaker" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /Dockerfile., *DEVICE_TYPE ]
  #   target: sagemaker
  #   context:
  #     <<: *TRAINING_CONTEXT
  # BuildSageMakerGPUPTTrainPy3DockerImage:
  #   <<: *TRAINING_REPOSITORY
  #   build: &PYTORCH_GPU_TRAINING_PY3 false
  #   image_size_baseline: 20000
  #   base_image_name: BuildE3GPUPTTrainPy3DockerImage
  #   device_type: &DEVICE_TYPE gpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   cuda_version: &CUDA_VERSION cu113
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *CUDA_VERSION, "-", *OS_VERSION, "-sagemaker" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /, *CUDA_VERSION, /Dockerfile.,
  #                        *DEVICE_TYPE ]
  #   target: sagemaker
  #   context:
  #     <<: *TRAINING_CONTEXT
  # BuildPyTorchExampleGPUTrainPy3DockerImage:
  #   <<: *TRAINING_REPOSITORY
  #   build: &PYTORCH_GPU_TRAINING_PY3 false
  #   enable_test_promotion: false
  #   image_size_baseline: 14000
  #   base_image_name: BuildE3GPUPTTrainPy3DockerImage
  #   device_type: &DEVICE_TYPE gpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   cuda_version: &CUDA_VERSION cu113
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *CUDA_VERSION, "-", *OS_VERSION,
  #                "-e3-example" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /example, /Dockerfile., *DEVICE_TYPE ]
  #   context:
  #     <<: *TRAINING_CONTEXT
  # BuildE3CPUPTInferencePy3DockerImage:
  #   <<: *INFERENCE_REPOSITORY
  #   build: &PYTORCH_CPU_INFERENCE_PY3 false
  #   enable_test_promotion: false
  #   image_size_baseline: 4899
  #   device_type: &DEVICE_TYPE cpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *OS_VERSION, "-e3" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /Dockerfile., *DEVICE_TYPE ]
  #   target: e3
  #   context:
  #     <<: *INFERENCE_CONTEXT
  # BuildE3GPUPTInferencePy3DockerImage:
  #   <<: *INFERENCE_REPOSITORY
  #   build: &PYTORCH_GPU_INFERENCE_PY3 false
  #   enable_test_promotion: false
  #   image_size_baseline: 14000
  #   device_type: &DEVICE_TYPE gpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   cuda_version: &CUDA_VERSION cu113
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *CUDA_VERSION, "-", *OS_VERSION, "-e3" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /, *CUDA_VERSION, /Dockerfile.,
  #                        *DEVICE_TYPE ]
  #   target: e3
  #   context:
  #     <<: *INFERENCE_CONTEXT
  # BuildSageMakerCPUPTInferencePy3DockerImage:
  #   <<: *INFERENCE_REPOSITORY
  #   build: &PYTORCH_CPU_INFERENCE_PY3 false
  #   image_size_baseline: 4899
  #   base_image_name: BuildE3CPUPTInferencePy3DockerImage
  #   device_type: &DEVICE_TYPE cpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *OS_VERSION, "-sagemaker" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /Dockerfile., *DEVICE_TYPE ]
  #   target: sagemaker
  #   context:
  #     <<: *INFERENCE_CONTEXT
  # BuildSageMakerGPUPTInferencePy3DockerImage:
  #   <<: *INFERENCE_REPOSITORY
  #   build: &PYTORCH_GPU_INFERENCE_PY3 false
  #   image_size_baseline: 14000
  #   base_image_name: BuildE3GPUPTInferencePy3DockerImage
  #   device_type: &DEVICE_TYPE gpu
  #   python_version: &DOCKER_PYTHON_VERSION py3
  #   tag_python_version: &TAG_PYTHON_VERSION py38
  #   cuda_version: &CUDA_VERSION cu113
  #   os_version: &OS_VERSION ubuntu20.04
  #   tag: !join [ *VERSION, "-", *DEVICE_TYPE, "-", *TAG_PYTHON_VERSION, "-", *CUDA_VERSION, "-", *OS_VERSION, "-sagemaker" ]
  #   docker_file: !join [ docker/, *SHORT_VERSION, /, *DOCKER_PYTHON_VERSION, /, *CUDA_VERSION, /Dockerfile.,
  #                        *DEVICE_TYPE ]
  #   target: sagemaker
  #   context:
  #     <<: *INFERENCE_CONTEXT
