ARG PYTHON=python3
ARG PYTORCH_VERSION=2.7.1
ARG TORCHTNT_VERSION=0.2.4
ARG TORCHAUDIO_VERSION=2.7.1
ARG TORCHVISION_VERSION=0.22.1
ARG TORCHDATA_VERSION=0.11.0
ARG GDRCOPY_VERSION=2.5
ARG TE_VERSION=2.3
ARG FLASH_ATTN_VERSION=2.7.4.post1
FROM 669063966089.dkr.ecr.us-west-2.amazonaws.com/pr-base:12.8.0-gpu-py312-cu128-ubuntu22.04-ec2-pr-5177-2025-08-18-21-56-10 as common

LABEL maintainer="Amazon AI"
LABEL dlc_major_version="1"
# has EFA PYTHON and CUDA 12.8
# This arg required to stop docker build waiting for region configuration while installing tz data from ubuntu 20
ARG PYTORCH_VERSION
ARG TORCHDATA_VERSION
ARG TORCHAUDIO_VERSION
ARG TORCHVISION_VERSION
ARG TORCHTNT_VERSION
ARG PYTHON
ARG GDRCOPY_VERSION
ARG TE_VERSION
ARG FLASH_ATTN_VERSION
ENV DEBIAN_FRONTEND=noninteractive
ENV LD_LIBRARY_PATH="/usr/local/lib:${LD_LIBRARY_PATH}"


ENV TORCH_NVCC_FLAGS="-Xfatbin -compress-all"
ENV DLC_CONTAINER_TYPE=training

RUN curl -o /license.txt https://aws-dlc-licenses.s3.amazonaws.com/pytorch-2.7/license.txt

COPY start_cuda_compat.sh /usr/local/bin/start_cuda_compat.sh
RUN chmod +x /usr/local/bin/start_cuda_compat.sh

COPY bash_telemetry.sh /usr/local/bin/bash_telemetry.sh
RUN chmod +x /usr/local/bin/bash_telemetry.sh
RUN echo 'source /usr/local/bin/bash_telemetry.sh' >> /etc/bash.bashrc

RUN pip install --no-cache-dir \
    numpy \
    "setuptools>=70.0.0"  \
    ninja \
    cython \
    pybind11 \
    mkl \
    mkl-include

# Install PyTorch
RUN pip install --no-cache-dir -U torch==${PYTORCH_VERSION} \
    torchvision==${TORCHVISION_VERSION} \
    torchaudio==${TORCHAUDIO_VERSION} \
    --index-url https://download.pytorch.org/whl/cu128 \
    && pip install --no-cache-dir -U torchtnt==${TORCHTNT_VERSION} \
    torchdata==${TORCHDATA_VERSION} \
    triton 

WORKDIR /

# Install GDRCopy which is a dependency of SM Distributed DataParallel binary
# The test binaries requires cuda driver library which could be found in conda
# So update the linker path to point to it to avoid -Lcuda not found
RUN cd /tmp \
 && git clone https://github.com/NVIDIA/gdrcopy.git -b v${GDRCOPY_VERSION} \
 && cd gdrcopy \
 && sed -ie '12s@$@ -L $(CUDA)/lib64/stubs@' tests/Makefile \
 && CUDA=${CUDA_HOME} make install \
 && rm -rf /tmp/gdrcopy


# Install flash attn and NVIDIA transformer engine.
# Optionally set NVTE_FRAMEWORK to avoid bringing in additional frameworks during TE install
ENV NVTE_FRAMEWORK=pytorch
# Install flash-attn using instructions from https://github.com/Dao-AILab/flash-attention#installation-and-features
# Set MAX_JOBS=4 to avoid OOM issues in installation process
RUN MAX_JOBS=4 pip install --no-cache-dir flash-attn==${FLASH_ATTN_VERSION} --no-build-isolation
# Install TE using instructions from https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/installation.html
RUN pip install --no-cache-dir git+https://github.com/NVIDIA/TransformerEngine.git@release_v${TE_VERSION} --no-build-isolation

RUN apt-get update \
 && apt-get -y upgrade --only-upgrade systemd \
 && apt-get install -y --allow-change-held-packages --no-install-recommends \
    libgl1-mesa-glx \
    curl \
    emacs \
    git \
    jq \
    unzip \
    vim \
    wget \
&& rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir \
    cryptography \
    pyOpenSSL \
    parso \
    typing \
    charset-normalizer \
    packaging \
    boto3 \
    PyYAML \
    scipy \
    click \
    psutil \
    ipython \
    ipykernel \
    pillow \
    h5py \
    fsspec \
    "idna>=3.7" \
    "tqdm>=4.66.3" \
    "requests>=2.32.0" \
    "urllib3>=2.5.0" \
    "awscli<2" \
    # opencv-python 4.12.0.88 reuqires numpy<2.3.0, which is not compatible with previous prod image(2.3.1)
    opencv-python==4.11.0.86 \
    mpi4py \
    tornado>=6.5.1 \
    s3torchconnector \
    fastai==2.8.2 \
    accelerate \
    # pin numpy requirement for fastai dependency
    # requires explicit declaration of spacy, thic, blis
    spacy \
    #thinc 8.3.6 is not compatible with numpy 1.26.4 (sagemaker doesn't support latest numpy)
    thinc==8.3.4 \
    blis \
    jinja2>=3.1.6 \
 && pip uninstall -y dataclasses

# Removing the cache as it is needed for security verification
RUN rm -rf /root/.cache | true
FROM common AS ec2

ARG PYTHON

COPY dockerd_entrypoint.sh /usr/local/bin/dockerd_entrypoint.sh
RUN chmod +x /usr/local/bin/dockerd_entrypoint.sh

RUN apt-get update \
 && apt-get upgrade -y \
 && apt-get autoremove -y \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

COPY setup_oss_compliance.sh setup_oss_compliance.sh
RUN bash setup_oss_compliance.sh ${PYTHON} && rm setup_oss_compliance.sh

# Removing the cache as it is needed for security verification
RUN rm -rf /root/.cache | true

ENTRYPOINT ["bash", "-m", "dockerd_entrypoint.sh"]
CMD ["/bin/bash"]

FROM common AS sagemaker

ARG PYTHON

# Copy workaround script for incorrect hostname
COPY changehostname.c /
COPY start_with_right_hostname.sh /usr/local/bin/start_with_right_hostname.sh
RUN chmod +x /usr/local/bin/start_with_right_hostname.sh

# Install SM packages
RUN pip install --no-cache-dir -U \
    smclarify \
    "sagemaker>=2,<3" \
    "sagemaker-experiments<1" \
    sagemaker-pytorch-training \
    sagemaker-training

# Install extra packages
RUN pip install --no-cache-dir -U \
    bokeh \
    imageio \
    numba \
    pandas \
    plotly \
    shap \
    scikit-learn \
    seaborn \
    # pinned for sagemaker==2.233.0
    cloudpickle 

RUN apt-get update \
 && apt-get upgrade -y \
 && apt-get autoremove -y \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

COPY setup_oss_compliance.sh setup_oss_compliance.sh
RUN bash setup_oss_compliance.sh ${PYTHON} && rm setup_oss_compliance.sh

# Removing the cache as it is needed for security verification
RUN rm -rf /root/.cache | true

ENTRYPOINT ["bash", "-m", "start_with_right_hostname.sh"]
CMD ["/bin/bash"]