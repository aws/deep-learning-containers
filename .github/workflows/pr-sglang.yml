name: PR - SGLang

on:
  pull_request:
    branches:
      - main
    paths:
      - "docker/sglang/**"

permissions:
  contents: read

concurrency:
  group: pr-sglang-${{ github.event.pull_request.number }}
  cancel-in-progress: true

jobs:
  check-changes:
    runs-on: ubuntu-latest
    outputs:
      sglang-sagemaker: ${{ steps.changes.outputs.sglang-sagemaker }}
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-python@v6
        with:
          python-version: "3.12"
      - uses: pre-commit/action@v3.0.1
        with:
          extra_args: --all-files
      - name: Detect file changes
        id: changes
        uses: dorny/paths-filter@v3
        with:
          filters: |
            sglang-sagemaker:
              - "docker/sglang/Dockerfile"

  build-sglang-image:
    needs: [check-changes]
    if: needs.check-changes.outputs.sglang-sagemaker == 'true'
    runs-on:
      - codebuild-runner-${{ github.run_id }}-${{ github.run_attempt }}
        fleet:x86-build-runner
    outputs:
      image-uri: ${{ steps.image-uri-build.outputs.IMAGE_URI }}
    steps:
      - uses: actions/checkout@v5
      - run: .github/scripts/runner_setup.sh
      - run: .github/scripts/buildkitd.sh

      - name: ECR login
        uses: ./.github/actions/ecr-authenticate
        with:
          aws_region: ${{ vars.AWS_REGION }}
          aws_account_id: ${{ vars.AWS_ACCOUNT_ID }}

      - name: Resolve image URI for build
        id: image-uri-build
        run: |
          IMAGE_URI=${{ vars.AWS_ACCOUNT_ID }}.dkr.ecr.${{ vars.AWS_REGION }}.amazonaws.com/ci:sglang-0.5.5-gpu-py312-cu129-ubuntu22.04-sagemaker-pr-${{ github.event.pull_request.number }}
          echo "Image URI to build: $IMAGE_URI"
          echo "IMAGE_URI=$IMAGE_URI" >> $GITHUB_ENV
          echo "IMAGE_URI=$IMAGE_URI" >> $GITHUB_OUTPUT

      - name: Build image
        run: |
          docker buildx build --progress plain \
            --build-arg CACHE_REFRESH="$(date +"%Y-%m-%d")" \
            --cache-to=type=inline \
            --cache-from=type=registry,ref=${IMAGE_URI} \
            --tag ${IMAGE_URI} \
            --target sglang-sagemaker \
            -f docker/sglang/Dockerfile .

      - name: Container push
        run: |
          docker push ${IMAGE_URI}
          docker rmi ${IMAGE_URI}

  sglang-local-benchmark-test:
    needs: [build-sglang-image]
    if: needs.build-sglang-image.result == 'success'
    runs-on:
      - codebuild-runner-${{ github.run_id }}-${{ github.run_attempt }}
        fleet:x86-g6xl-runner
    steps:
      - name: Checkout DLC source
        uses: actions/checkout@v5

      - name: Container pull
        uses: ./.github/actions/ecr-authenticate
        with:
          aws_region: ${{ vars.AWS_REGION }}
          aws_account_id: ${{ vars.AWS_ACCOUNT_ID }}
          image_uri: ${{ needs.build-sglang-image.outputs.image-uri }}

      - name: Setup for SGLang datasets
        run: |
          mkdir -p /tmp/sglang/dataset
          if [ ! -f /tmp/sglang/dataset/ShareGPT_V3_unfiltered_cleaned_split.json ]; then
              echo "Downloading ShareGPT dataset..."
              wget -P /tmp/sglang/dataset https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json
          else
              echo "ShareGPT dataset already exists. Skipping download."
          fi

      - name: Start container
        run: |
          CONTAINER_ID=$(docker run -d -it --rm --gpus=all \
            -v ${HOME}/.cache/huggingface:/root/.cache/huggingface \
            -v /tmp/sglang/dataset:/dataset \
            -p 30000:30000 \
            -e SM_SGLANG_MODEL_PATH=Qwen/Qwen3-0.6B \
            -e SM_SGLANG_REASONING_PARSER=qwen3 \
            -e SM_SGLANG_HOST=127.0.0.1 \
            -e SM_SGLANG_PORT=30000 \
            -e HF_TOKEN=${{ secrets.HUGGING_FACE_HUB_TOKEN }} \
            ${{ needs.build-sglang-image.outputs.image-uri }})
          echo "CONTAINER_ID=$CONTAINER_ID" >> $GITHUB_ENV
          echo "Waiting for container startup ..."
          sleep 300s
          docker logs ${CONTAINER_ID}

      - name: Run SGLang tests
        run: |
          docker exec ${CONTAINER_ID} python3 -m sglang.bench_serving \
          --backend sglang \
          --host 127.0.0.1 --port 30000 \
          --num-prompts 1000 \
          --model Qwen/Qwen3-0.6B \
          --dataset-name sharegpt \
          --dataset-path /dataset/ShareGPT_V3_unfiltered_cleaned_split.json

      - name: Cleanup container and images
        if: always()
        uses: ./.github/actions/container-cleanup
        with:
          container_id: ${{ env.CONTAINER_ID }}

  sglang-lang-test:
    needs: [build-sglang-image]
    if: needs.build-sglang-image.result == 'success'
    runs-on:
      - codebuild-runner-${{ github.run_id }}-${{ github.run_attempt }}
        fleet:x86-g6exl-runner
    steps:
      - name: Checkout DLC source
        uses: actions/checkout@v5

      - name: Container pull
        uses: ./.github/actions/ecr-authenticate
        with:
          aws_region: ${{ vars.AWS_REGION }}
          aws_account_id: ${{ vars.AWS_ACCOUNT_ID }}
          image_uri: ${{ needs.build-sglang-image.outputs.image-uri }}

      - name: Checkout SGLang tests
        uses: actions/checkout@v5
        with:
          repository: sgl-project/sglang
          ref: v0.5.5
          path: sglang_source

      - name: Start container
        run: |
          CONTAINER_ID=$(docker run -d -it --rm --gpus=all --entrypoint /bin/bash \
            -v ${HOME}/.cache/huggingface:/root/.cache/huggingface \
            -v ./sglang_source:/workdir --workdir /workdir \
            -e HF_TOKEN=${{ secrets.HUGGING_FACE_HUB_TOKEN }} \
            ${{ needs.build-sglang-image.outputs.image-uri }})
          echo "CONTAINER_ID=$CONTAINER_ID" >> $GITHUB_ENV

      - name: Setup for SGLang tests
        run: |
          docker exec ${CONTAINER_ID} sh -c '
            set -eux

            bash scripts/ci/ci_install_dependency.sh
          '

      - name: Run SGLang tests
        run: |
          docker exec ${CONTAINER_ID} sh -c '
            set -eux
            nvidia-smi

            # Frontend Test
            cd /workdir/test/lang
            python3 run_suite.py --suite per-commit
          '

      - name: Cleanup container and images
        if: always()
        uses: ./.github/actions/container-cleanup
        with:
          container_id: ${{ env.CONTAINER_ID }}

  sglang-sagemaker-endpoint-test:
    needs: [build-sglang-image]
    if: needs.build-sglang-image.result == 'success'
    runs-on:
      - codebuild-runner-${{ github.run_id }}-${{ github.run_attempt }}
        fleet:default-runner
    steps:
      - name: Checkout DLC source
        uses: actions/checkout@v5

      - name: Run example tests
        run: |
          python3 -m pytest -vs test/test_example.py
