########################################################
#  _____ ____ ____    ___
# | ____/ ___|___ \  |_ _|_ __ ___   __ _  __ _  ___
# |  _|| |     __) |  | || '_ ` _ \ / _` |/ _` |/ _ \
# | |__| |___ / __/   | || | | | | | (_| | (_| |  __/
# |_____\____|_____| |___|_| |_| |_|\__,_|\__, |\___|
#                                         |___/
#  ____           _
# |  _ \ ___  ___(_)_ __   ___
# | |_) / _ \/ __| | '_ \ / _ \
# |  _ <  __/ (__| | |_) |  __/
# |_| \_\___|\___|_| .__/ \___|
#                  |_|
########################################################

FROM tensorflow/serving:2.19.0-devel-gpu as build_image

FROM nvidia/cuda:12.2.0-base-ubuntu22.04 AS base_image

ENV DEBIAN_FRONTEND=noninteractive \
    LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/lib"

RUN apt-get update \
 && apt-get upgrade -y \
 && apt-get autoremove -y \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

FROM base_image AS ec2

LABEL maintainer="Amazon AI"
LABEL dlc_major_version="1"

ARG PYTHON=python3.12
ARG PYTHON_PIP=python3-pip
ARG PIP=pip3
ARG PYTHON_VERSION=3.12.10
ARG TFS_SHORT_VERSION=2.19
ARG CUDA_DASH=12-2

ARG TF_SERVING_VERSION_GIT_COMMIT=c491ba6554e4ea41cd4ae0eba9012b762fb2b455

# ENV variable to be passed to SageMaker stage
ENV PIP=${PIP}
ENV PYTHON=${PYTHON}
ENV PYTHON_VERSION=${PYTHON_VERSION}


ENV CUDA_DASH=12-2
ENV NCCL_VERSION=2.18.3-1+cuda12.2
ENV CUDNN_VERSION=8.9.4.25-1+cuda12.2

# See http://bugs.python.org/issue19846
ENV LANG=C.UTF-8
ENV PYTHONDONTWRITEBYTECODE=1
# Python wonâ€™t try to write .pyc or .pyo files on the import of source modules
ENV PYTHONUNBUFFERED=1
ENV MODEL_BASE_PATH=/models
# The only required piece is the model name in order to differentiate endpoints
ENV MODEL_NAME=model
# Fix for the interactive mode during an install in step 21
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y --no-install-recommends \
        curl

RUN curl -sSL --retry 5 https://raw.githubusercontent.com/tensorflow/serving/${TF_SERVING_VERSION_GIT_COMMIT}/tensorflow_serving/tools/docker/setup.sources.sh | sh


# First install basic tools needed for Python compilation
RUN apt-get update \
 && apt-get install -y --no-install-recommends \
    ca-certificates \
    curl \
    wget \
    gnupg2 \
    build-essential \
    zlib1g-dev \
    libssl-dev \
    libbz2-dev \
    liblzma-dev \
    libffi-dev \
    libreadline-dev \
    libncursesw5-dev \
    libsqlite3-dev \
    libgdbm-dev \
    tk-dev \
    libc6-dev \
    openssl \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

RUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb && \
    dpkg -i cuda-keyring_1.0-1_all.deb && \
    rm cuda-keyring_1.0-1_all.deb && \
    apt-get update
    
# Install python
RUN wget https://www.python.org/ftp/python/${PYTHON_VERSION}/Python-${PYTHON_VERSION}.tgz \
 && tar -xvf Python-${PYTHON_VERSION}.tgz \
 && cd Python-${PYTHON_VERSION} \
 && ./configure && make && make install -j \
 && rm -rf ../Python-${PYTHON_VERSION}*

# Install libssl1.1 from Ubuntu 20.04 to satisfy CUDA dependencies
RUN wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1-1ubuntu2.1~18.04.23_amd64.deb \
 && dpkg -i libssl1.1_1.1.1-1ubuntu2.1~18.04.23_amd64.deb \
 && rm libssl1.1_1.1.1-1ubuntu2.1~18.04.23_amd64.deb

RUN apt-get update \
 && apt-get install -y --no-install-recommends --allow-unauthenticated --allow-downgrades \
    cuda-command-line-tools-${CUDA_DASH} \
    cuda-cupti-${CUDA_DASH} \
    cuda-libraries-${CUDA_DASH} \
    cuda-nvprune-${CUDA_DASH} \
    cuda-nvrtc-${CUDA_DASH} \
    cuda-nvrtc-dev-${CUDA_DASH} \
    cuda-cudart-dev-${CUDA_DASH} \
    cuda-nvcc-${CUDA_DASH} \
    libcufft-${CUDA_DASH} \
    libcufft-dev-${CUDA_DASH} \
    libcurand-${CUDA_DASH} \
    libcurand-dev-${CUDA_DASH} \
    libcusolver-${CUDA_DASH} \
    libcusolver-dev-${CUDA_DASH} \
    libcusparse-dev-${CUDA_DASH} \
    #cuda-cublas-dev not available with 10-1, install libcublas instead
    libcublas-${CUDA_DASH} \
    libcublas-dev-${CUDA_DASH} \
    libcudnn8=${CUDNN_VERSION} \
    libcudnn8-dev=${CUDNN_VERSION} \
    libnccl2=${NCCL_VERSION} \
    libnccl-dev=${NCCL_VERSION} \
    libgomp1 \
    emacs \
    git \
    unzip \
    vim \
    libfreetype6-dev \
    pkg-config \
    software-properties-common \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*


RUN ${PIP} --no-cache-dir install --upgrade \
    pip \
    setuptools

# Upgrade libsasl2-2 for fixing cyrus-sasl2 related CVE
RUN apt-get install -y --only-upgrade libsasl2-2

# Some TF tools expect a "python" binary
RUN ln -s $(which ${PYTHON}) /usr/local/bin/python \
 && ln -s $(which ${PIP}) /usr/bin/pip

RUN apt-get update \
 && apt-get -y install --no-install-recommends \
    curl \
    gnupg2 \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

RUN ${PIP} install -U --no-cache-dir \
    "awscli<2" \
    boto3 \
    "cython<3.0" \
    gevent \
    requests \
    grpcio \
    "protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3" \
    packaging \
# using --no-dependencies to avoid installing tensorflow binary
 && ${PIP} install --no-dependencies --no-cache-dir \
    tensorflow-serving-api-gpu=="2.19.0"


# Install TF Serving GPU pkg
COPY --from=build_image /usr/local/bin/tensorflow_model_server /usr/bin/tensorflow_model_server

# Expose gRPC and REST port
EXPOSE 8500 8501

# Set where models should be stored in the container
RUN mkdir -p ${MODEL_BASE_PATH}

ADD https://raw.githubusercontent.com/aws/deep-learning-containers/master/src/deep_learning_container.py /usr/local/bin/deep_learning_container.py

RUN chmod +x /usr/local/bin/deep_learning_container.py

COPY bash_telemetry.sh /usr/local/bin/bash_telemetry.sh

RUN chmod +x /usr/local/bin/bash_telemetry.sh

RUN echo 'source /usr/local/bin/bash_telemetry.sh' >> /etc/bash.bashrc

# Create a script that runs the model server so we can use environment variables
# while also passing in arguments from the docker command line
RUN echo '#!/bin/bash \n\n' > /usr/bin/tf_serving_entrypoint.sh \
 && echo '/usr/bin/tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=${MODEL_NAME} --model_base_path=${MODEL_BASE_PATH}/${MODEL_NAME} "$@"' >> /usr/bin/tf_serving_entrypoint.sh \
 && chmod +x /usr/bin/tf_serving_entrypoint.sh

RUN HOME_DIR=/root \
 && curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \
 && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \
 && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \
 && chmod +x /usr/local/bin/testOSSCompliance \
 && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \
 && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \
 && rm -rf ${HOME_DIR}/oss_compliance*

RUN curl https://aws-dlc-licenses.s3.amazonaws.com/tensorflow-${TFS_SHORT_VERSION}/license.txt -o /license.txt

RUN rm -rf /tmp/*

CMD ["/usr/bin/tf_serving_entrypoint.sh"]

#################################################################
#  ____                   __  __       _
# / ___|  __ _  __ _  ___|  \/  | __ _| | _____ _ __
# \___ \ / _` |/ _` |/ _ \ |\/| |/ _` | |/ / _ \ '__|
#  ___) | (_| | (_| |  __/ |  | | (_| |   <  __/ |
# |____/ \__,_|\__, |\___|_|  |_|\__,_|_|\_\___|_|
#              |___/
#  ___                              ____           _
# |_ _|_ __ ___   __ _  __ _  ___  |  _ \ ___  ___(_)_ __   ___
#  | || '_ ` _ \ / _` |/ _` |/ _ \ | |_) / _ \/ __| | '_ \ / _ \
#  | || | | | | | (_| | (_| |  __/ |  _ <  __/ (__| | |_) |  __/
# |___|_| |_| |_|\__,_|\__, |\___| |_| \_\___|\___|_| .__/ \___|
#                      |___/                        |_|
#################################################################

FROM ec2 AS sagemaker

LABEL maintainer="Amazon AI"
LABEL dlc_major_version="1"

# Specify accept-bind-to-port LABEL for inference pipelines to use SAGEMAKER_BIND_TO_PORT
# https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-real-time.html
LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true
LABEL com.amazonaws.sagemaker.inference.cuda.verified_versions=12.2

ARG TFS_SHORT_VERSION=2.19
ENV SAGEMAKER_TFS_VERSION="${TFS_SHORT_VERSION}"
ENV PATH="$PATH:/sagemaker"

# nginx + njs
RUN curl -s http://nginx.org/keys/nginx_signing.key | apt-key add - \
 && echo 'deb http://nginx.org/packages/ubuntu/ jammy nginx' >> /etc/apt/sources.list \
 && apt-get update \
 && apt-get -y install --no-install-recommends \
    nginx \
    nginx-module-njs \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

# the Pins are for the TFS SageMaker Toolkit
RUN ${PIP} install -U --no-cache-dir \
    falcon==3.0.1 \
    "gunicorn>=22.0.0"

COPY ./sagemaker /sagemaker

COPY start_cuda_compat.sh /usr/local/bin/start_cuda_compat.sh
COPY dockerd_entrypoint.sh /usr/local/bin/dockerd_entrypoint.sh
RUN chmod +x /usr/local/bin/start_cuda_compat.sh
RUN chmod +x /usr/local/bin/dockerd_entrypoint.sh

# Expose gRPC and REST port
EXPOSE 8500 8501

RUN HOME_DIR=/root \
 && curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \
 && unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \
 && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \
 && chmod +x /usr/local/bin/testOSSCompliance \
 && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \
 && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \
 && rm -rf ${HOME_DIR}/oss_compliance*

RUN rm -rf /tmp/*

ENTRYPOINT ["bash", "-m", "/usr/local/bin/dockerd_entrypoint.sh"]
CMD ["/usr/bin/tf_serving_entrypoint.sh"]
