ARG CUDA_VERSION=12.8.1
ARG IMAGE_DISTRO=ubuntu22.04
ARG PYTHON_VERSION=3.12

##############################################################################
FROM nvcr.io/nvidia/cuda:${CUDA_VERSION}-devel-${IMAGE_DISTRO} AS base

ARG TORCH_CUDA_ARCH_LIST="7.5"
ENV TORCH_CUDA_ARCH_LIST=${TORCH_CUDA_ARCH_LIST}
ENV UV_TORCH_BACKEND=cu128
ARG VLLM_FA_CMAKE_GPU_ARCHES="75"
ENV VLLM_FA_CMAKE_GPU_ARCHES=${VLLM_FA_CMAKE_GPU_ARCHES}

ENV DEBIAN_FRONTEND=noninteractive
RUN apt update
RUN apt upgrade -y
RUN apt install -y --no-install-recommends \
    curl \
    git \
    libibverbs-dev \
    zlib1g-dev \
    libnuma-dev

RUN apt clean && \
    rm -rf /var/lib/apt/lists/* && \
    rm -rf /var/cache/apt/archives


ENV CC=/usr/bin/gcc
ENV CXX=/usr/bin/g++
RUN curl -LsSf https://astral.sh/uv/install.sh | env UV_INSTALL_DIR=/usr/local/bin sh

WORKDIR /workspace

ARG PYTHON_VERSION
RUN uv venv -p ${PYTHON_VERSION} --seed --python-preference only-managed
ENV VIRTUAL_ENV=/workspace/.venv
ENV PATH=${VIRTUAL_ENV}/bin:${PATH}
ENV CUDA_HOME=/usr/local/cuda
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

RUN apt-get update && apt install -y wget

ARG TORCH_URL=https://framework-binaries.s3.us-west-2.amazonaws.com/pytorch/v2.7.0/arm64/cu128/torch-2.7.0%2Bcu128-cp312-cp312-manylinux_2_28_aarch64.whl
ARG TORCHVISION_URL=https://framework-binaries.s3.us-west-2.amazonaws.com/pytorch/v2.7.0/arm64/cu128/torchvision-0.22.0%2Bcu128-cp312-cp312-linux_aarch64.whl
ARG TORCHAUDIO_URL=https://framework-binaries.s3.us-west-2.amazonaws.com/pytorch/v2.7.0/arm64/cu128/torchaudio-2.7.0%2Bcu128-cp312-cp312-linux_aarch64.whl

RUN uv pip install --no-cache-dir -U \
    ${TORCH_URL} \
    ${TORCHVISION_URL} \
    ${TORCHAUDIO_URL}

RUN uv pip install --extra-index-url https://download.pytorch.org/whl/nightly/pytorch-triton/ pytorch_triton==3.3.0

##############################################################################
FROM base AS build-base
RUN mkdir /wheels

RUN uv pip install -U build cmake ninja pybind11 setuptools wheel requests numpy
RUN export MAX_JOBS=15

###############################################################################
FROM build-base AS build-xformers
ARG XFORMERS_REF=v0.0.30
ARG XFORMERS_BUILD_VERSION=0.0.30+cu128
ENV BUILD_VERSION=${XFORMERS_BUILD_VERSION}
RUN git clone https://github.com/facebookresearch/xformers.git && \
    cd xformers && \
    git checkout ${XFORMERS_REF} && \
    git submodule sync && \
    git submodule update --init --recursive -j 8 && \
    uv build --wheel --no-build-isolation -o /wheels

###############################################################################
FROM build-base AS build-vllm

RUN uv pip install \
    packaging>=24.2 \
    setuptools-scm>=8 \
    torch==2.7.0 \
    jinja2>=3.1.6 \
    regex 

RUN git clone https://github.com/vllm-project/vllm.git && \
    cd vllm && \
    git checkout v0.10.2 && \
    git submodule sync && \
    git submodule update --init --recursive -j 8 && \
    MAX_JOBS=16 uv build --wheel --no-build-isolation -o /wheels

###############################################################################
FROM base AS vllm-openai
COPY --from=build-vllm /wheels/* wheels/
COPY --from=build-xformers /wheels/* wheels/

RUN git clone https://github.com/flashinfer-ai/flashinfer.git --recursive && \
    cd flashinfer && \
    python -c "import torch; print(torch.__version__, torch.version.cuda)" && \
    git checkout v0.2.14.post1 && \
    export FLASHINFER_CUDA_ARCH_LIST="7.5" && \
    python -m flashinfer.aot && \
    MAX_JOBS=16 uv pip install --system --no-build-isolation . && \
    python3 -m flashinfer --download-cubin || echo "WARNING: Failed to download flashinfer cubins."

    
RUN uv pip install wheels/* && \
    rm -r wheels

RUN uv pip install accelerate hf_transfer modelscope bitsandbytes timm boto3 runai-model-streamer runai-model-streamer[s3] tensorizer

RUN uv clean

RUN export PATH="$(dirname $(realpath .venv/bin/python)):$PATH"

RUN uv pip install -U build cmake ninja pybind11 setuptools==79.0.1 wheel

# Enable hf-transfer for faster downloads
ENV HF_HUB_ENABLE_HF_TRANSFER=1
RUN uv pip install datasets aiohttp

ARG NSYS_URL=https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2025_3/
ARG NSYS_PKG=nsight-systems-cli-2025.3.1_2025.3.1.90-1_arm64.deb

RUN apt-get update && apt install -y wget libglib2.0-0
RUN wget ${NSYS_URL}${NSYS_PKG} && \
    dpkg -i $NSYS_PKG && \
    rm $NSYS_PKG
RUN apt install -y --no-install-recommends tmux cmake

# Install required build tool
RUN uv pip install ninja

ARG PYTHON="python3"
LABEL maintainer="Amazon AI"
LABEL dlc_major_version="1"
ARG EFA_VERSION="1.43.2"
ENV DEBIAN_FRONTEND=noninteractive \
    LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    DLC_CONTAINER_TYPE=general \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONIOENCODING=UTF-8 \
    LD_LIBRARY_PATH="/usr/local/lib:/opt/amazon/ofi-nccl/lib/aarch64-linux-gnu:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}" \
    PATH="/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/usr/local/cuda/bin:${PATH}"


WORKDIR /

COPY install_efa.sh install_efa.sh
COPY deep_learning_container.py /usr/local/bin/deep_learning_container.py
COPY bash_telemetry.sh /usr/local/bin/bash_telemetry.sh
COPY dockerd_entrypoint.sh /usr/local/bin/dockerd_entrypoint.sh
RUN chmod +x /usr/local/bin/deep_learning_container.py && \
    chmod +x /usr/local/bin/bash_telemetry.sh && \
    chmod +x /usr/local/bin/dockerd_entrypoint.sh && \
    echo 'source /usr/local/bin/bash_telemetry.sh' >> /etc/bash.bashrc && \
    # Install EFA
    bash install_efa.sh ${EFA_VERSION} && \
    rm install_efa.sh

RUN apt-get update && \
    apt-get upgrade -y && \
    apt-get install -y --allow-change-held-packages --no-install-recommends unzip && \
    apt-get clean && \
    HOME_DIR=/root && \
    curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip && \
    unzip ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ && \
    cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance && \
    chmod +x /usr/local/bin/testOSSCompliance && \
    chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh && \
    ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} && \
    ln -s /usr/bin/python3 /usr/bin/python && \
    rm -rf ${HOME_DIR}/oss_compliance* && \
    rm -rf /tmp/tmp* && \
    rm -rf /tmp/uv* && \
    rm -rf /var/lib/apt/lists/* && \
    rm -rf /root/.cache | true

RUN mkdir -p /tmp/nvjpeg && \
    cd /tmp/nvjpeg && \
    wget https://developer.download.nvidia.com/compute/cuda/redist/libnvjpeg/linux-aarch64/libnvjpeg-linux-aarch64-12.4.0.76-archive.tar.xz && \
    tar -xvf libnvjpeg-linux-aarch64-12.4.0.76-archive.tar.xz && \
    rm -rf /usr/local/cuda/targets/sbsa-linux/lib/libnvjpeg* && \
    rm -rf /usr/local/cuda/targets/sbsa-linux/include/nvjpeg.h && \
    cp libnvjpeg-linux-aarch64-12.4.0.76-archive/lib/libnvjpeg* /usr/local/cuda/targets/sbsa-linux/lib/ && \
    cp libnvjpeg-linux-aarch64-12.4.0.76-archive/include/* /usr/local/cuda/targets/sbsa-linux/include/ && \
    rm -rf /tmp/nvjpeg && \
    rm -rf /usr/local/cuda/bin/cuobjdump* && \
    rm -rf /usr/local/cuda/bin/nvdisasm*

ENTRYPOINT ["/usr/local/bin/dockerd_entrypoint.sh"]