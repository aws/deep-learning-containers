#!/bin/bash

set -ex

TE_VERSION=$(pip show transformer_engine | awk '/^Version:/ {split($2, v, "."); print v[1] "." v[2]}')
PT_VERSION=$(python -c "import torch; print(torch.__version__)")

git clone --branch release_v${TE_VERSION} https://github.com/NVIDIA/TransformerEngine.git
cd TransformerEngine/tests/pytorch

function version { echo "$@" | awk -F. '{ printf("%d%03d%03d%03d\n", $1,$2,$3,$4); }'; }

if [ $(version ${TE_VERSION}) -ge $(version "1.0") ] || [ $(version ${PT_VERSION}) -ge $(version "2.2") ]; then
  # Test TransformerEngine 1.0 and above or PyTorch 2.2 and above
  # https://github.com/microsoft/onnxruntime/issues/17166
  SYSTEM_VERSION_COMPAT=0 pip install pytest==7.2 onnxruntime==1.17.3

  # NOTE: Disable few tests due to following issue. TE acknowledges issue and confirm we can skip.
  # https://github.com/NVIDIA/TransformerEngine/issues/666
  pytest -v -s test_sanity.py
  pytest -v -s test_deferred_init.py
  # PYTORCH_JIT=0 NVTE_TORCH_COMPILE=0 NVTE_ALLOW_NONDETERMINISTIC_ALGO=0 pytest -v -s test_numerics.py
  PYTORCH_JIT=0 NVTE_TORCH_COMPILE=0 NVTE_ALLOW_NONDETERMINISTIC_ALGO=0 pytest -v -s test_cuda_graphs.py
  pytest -v -s test_jit.py
  # NVTE_TORCH_COMPILE=0 pytest -v -s fused_attn/test_fused_attn.py # 8.9.2
  pytest -v -s test_fused_rope.py
  # NVTE_TORCH_COMPILE=0 pytest -v -s test_onnx_export.py # 9.1.1
  pytest -v -s test_float8tensor.py

else
  # Test TransformerEngine below 1.0 or PyTorch below 2.2
  # https://github.com/microsoft/onnxruntime/issues/17166
  SYSTEM_VERSION_COMPAT=0 pip install pytest==6.2.5 onnxruntime==1.17.3 onnx

  # NOTE: Disable few test due to following issue. TE acknowledges issue and confirm we can skip.
  # https://github.com/NVIDIA/TransformerEngine/issues/666
  pytest -v -s test_sanity.py
  PYTORCH_JIT=0 NVTE_ALLOW_NONDETERMINISTIC_ALGO=0 pytest -v -s test_numerics.py
  pytest -v -s test_jit.py
  NVTE_TORCH_COMPILE=0 pytest -v -s test_onnx_export.py

fi
