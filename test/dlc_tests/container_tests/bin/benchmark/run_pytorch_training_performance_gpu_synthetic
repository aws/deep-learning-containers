#!/bin/bash

PYTHON_VERSION=$(python -c 'import sys; print(sys.version_info[0])' | tr -d "'")
if [ "$PYTHON_VERSION" -eq 2 ]
then
  exit 0
fi
TIMESTAMP=$(date "+%Y-%m-%d-%H-%M-%S")
HOME_DIR=/test/benchmark
BIN_DIR=${HOME_DIR}/bin
LOG_DIR=${HOME_DIR}/logs/gpu
LOG_FILE=synthetic_results_${COMMIT_INFO}_${TIMESTAMP}.txt

mkdir -p ${HOME_DIR}
mkdir -p ${BIN_DIR}
mkdir -p ${LOG_DIR}

set -e
cd ${HOME_DIR}
git clone https://github.com/HewlettPackard/dlcookbook-dlbs.git ./dlbs
source dlbs/scripts/environment.sh
sed -i "s/model = DDP(model, shared_param=True)/model = DDP(model, [opts['local_rank']], opts['local_rank'])/g" dlbs/python/pytorch_benchmarks/benchmarks.py
sed -i '/from apex.fp16_utils import network_to_half, prep_param_lists, model_grads_to_master_grads, master_params_to_model_params/,/raise ImportError("Please install apex from https:\/\/www.github.com\/nvidia\/apex to run this example.")/d' dlbs/python/pytorch_benchmarks/benchmarks.py
sed -i '/try:[ ]*$/{N;s/try:\s*from apex.parallel import DistributedDataParallel as DDP/from torch.nn.parallel import DistributedDataParallel as DDP/}' dlbs/python/pytorch_benchmarks/benchmarks.py
export OMP_NUM_THREADS=8
python -m torch.distributed.launch --nproc_per_node=8 dlbs/python/pytorch_benchmarks/benchmarks.py --model resnet50 --batch_size=64 --device gpu --cudnn_fastest --dist_backend=nccl  2>&1 | tee ${LOG_DIR}/${LOG_FILE}
echo Benchmark Results: >&2
echo PyTorch Training py"${PYTHON_VERSION}" gpu synthetic>&2
tail -3 ${LOG_DIR}/${LOG_FILE} >&2 # Display only the results to console
aws s3 cp ${LOG_DIR}/"${LOG_FILE}" s3://dlinfra-dlc-cicd-performance/pytorch/ec2/training/gpu/py"${PYTHON_VERSION}"/"${LOG_FILE}"
echo To retrieve complete benchmark log, check s3://dlinfra-dlc-cicd-performance/pytorch/ec2/training/gpu/py"${PYTHON_VERSION}"/"${LOG_FILE}" >&2
set +e

exit 0
