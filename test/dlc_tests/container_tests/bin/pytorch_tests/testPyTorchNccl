#!/bin/bash

set -e

export HOME_DIR=/test
export LOG_DIR=${HOME_DIR}/logs
export AWS_LOG_DIR=$LOG_DIR/aws_log

# check GPU status
if nvidia-smi &> /dev/null; then
   DEVICE="cuda"
   NUM_GPUS=$(nvidia-smi -L | wc -l)
else
   DEVICE="cpu"
   NUM_GPUS=0
fi

source /test/bin/pytorch_tests/installPyTorchBenchmarkRepository

export USE_INDUCTOR=$1
echo testPyTorchNCCL: USE_INDUCTOR, $USE_INDUCTOR

# may encounter cuda OOM if used too many processes. The benchmark repo hardcodes the batchsize for now.
export WORLD_SIZE=$(($NUM_GPUS < 4 ? $NUM_GPUS : 4))
# run NCCL benchmarking with 2 GPUS and 1 local node (resnet will use torchvision)
python userbenchmark/ddp_experiments/run.py \
    --ngpus $WORLD_SIZE \
    --distributed ddp \
    --nodes 1 \
    --cluster local \
    --filter_models resnet50 \
    --timeout 10 \
    --job_dir $AWS_LOG_DIR \
    --nccl-socket-ifname eth0

# generate the result csv
JOB_ID=$(ls $AWS_LOG_DIR | grep .out | head -n 1 | cut -d'_' -f 1)
python userbenchmark/ddp_experiments/parse_ddp.py \
    --job_id $JOB_ID \
    --results_dir $AWS_LOG_DIR \
    --csv_out > $AWS_LOG_DIR/aws_res.csv
echo testPyTorchNCCL: AWS-PyTorch test results && cat $AWS_LOG_DIR/aws_res.csv
exit 0