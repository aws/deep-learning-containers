#!/bin/bash

set -e

HOME_DIR=/test
BIN_DIR=${HOME_DIR}/bin
LOG_DIR=${HOME_DIR}/logs

source ${BIN_DIR}/pytorch_tests/setupPyTorchBackendTest

AWS_LOG_DIR=$LOG_DIR/aws_gloo_log/
OSS_LOG_DIR=$LOG_DIR/oss_gloo_log/

TRAINING_LOG=${LOG_DIR}/pytorch_train_gloo.log

echo "Training resnet18 using PyTorch Gloo... This may take a few minutes. You can follow progress on the log file : $TRAINING_LOG"
set +e
if [ ${NVIDIA_SMI_RETURN_VAL} -eq 0 ]; then
  python -m torch.distributed.launch --nproc_per_node=${NUM_GPU} \
  dlbs/python/pytorch_benchmarks/benchmarks.py \
  --model resnet18 --batch_size=32 --device gpu --cudnn_fastest --dist_backend=gloo > $TRAINING_LOG 2>&1
else
  python -m torch.distributed.launch \
  dlbs/python/pytorch_benchmarks/benchmarks.py \
  --model resnet18 --batch_size=32 --device cpu --dist_backend=gloo > $TRAINING_LOG 2>&1
fi
RETURN_VAL=`echo $?`
set -e

if [ ${RETURN_VAL} -eq 0 ]; then
    echo "Training resnet18 Complete using PyTorch Gloo."
else
    echo "Training resnet18 Failed using PyTorch Gloo."
    cat $TRAINING_LOG
    exit 1
fi


exit 0