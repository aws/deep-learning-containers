FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/mxnet-inference:1.8.0-cpu-py37

# Specify accept-bind-to-port LABEL for inference pipelines to use SAGEMAKER_BIND_TO_PORT
# https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-real-time.html
LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true
# Specify multi-models LABEL to indicate container is capable of loading and serving multiple models concurrently
# https://docs.aws.amazon.com/sagemaker/latest/dg/build-multi-model-build-container.html
LABEL com.amazonaws.sagemaker.capabilities.multi-models=true

LABEL maintainer="Amazon AI"
LABEL dlc_major_version="1"

ARG PYTHON_VERSION=3.7.10

RUN apt-get update \
 && apt-get -y upgrade \
 && apt-get autoremove -y \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*

ARG TORCH_VER=1.8.0+cpu
ARG TORCH_VISION_VER=0.9.0+cpu
ARG NUMPY_VER=1.19.5
ARG AUTOGLUON_VERSION=0.3.1

RUN pip --no-cache-dir install --upgrade --trusted-host pypi.org --trusted-host files.pythonhosted.org pip \
 && pip --no-cache-dir install --upgrade wheel setuptools \
 && pip uninstall -y dataclasses \
 && pip install --no-cache-dir -U torch==${TORCH_VER} torchvision==${TORCH_VISION_VER} -f https://download.pytorch.org/whl/torch_stable.html \
    numpy==${NUMPY_VER} \
    autogluon==${AUTOGLUON_VERSION}

EXPOSE 8080 8081
ENTRYPOINT ["python", "/usr/local/bin/dockerd-entrypoint.py"]
CMD ["multi-model-server" "--start" "--mms-config" "/home/model-server/config.properties"]