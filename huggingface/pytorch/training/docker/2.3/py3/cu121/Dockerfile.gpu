# https://github.com/aws/deep-learning-containers/blob/master/available_images.md
# refer to the above page to pull latest Pytorch image

# docker image region us-west-2
FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker

LABEL maintainer="Amazon AI"
LABEL dlc_major_version="2"

# version args
ARG TRANSFORMERS_VERSION
ARG DATASETS_VERSION
ARG HUGGINGFACE_HUB_VERSION=0.25.1
ARG DIFFUSERS_VERSION=0.31.0
ARG EVALUATE_VERSION=0.4.3
ARG ACCELERATE_VERSION=1.1.0
ARG TRL_VERSION=0.11.4
ARG PEFT_VERSION=0.13.2
ARG FLASH_ATTN_VERSION=2.6.3
ARG NINJA_VERSION=1.11.1
ARG PYTHON=python3

# TODO: Remove when the base image is updated
RUN pip install --upgrade pip \
 && pip uninstall -y transformer-engine flash-attn pyarrow cryptography \
 && pip install --no-cache-dir -U pyarrow cryptography pyopenssl Pillow \
 && pip --no-cache-dir install --upgrade wheel setuptools \
 && pip install --no-cache-dir -U "werkzeug==3.0.6" 

# install Hugging Face libraries and its dependencies
RUN pip install --no-cache-dir \
	# hf_transfer will be a built-in feature, remove the extra then
    huggingface_hub[hf_transfer]==${HUGGINGFACE_HUB_VERSION} \
	transformers[sklearn,sentencepiece,audio,vision,pipelines]==${TRANSFORMERS_VERSION} \
	datasets==${DATASETS_VERSION} \
	diffusers==${DIFFUSERS_VERSION} \
	Jinja2 \
	tensorboard \
	bitsandbytes \
	evaluate==${EVALUATE_VERSION} \
	accelerate==${ACCELERATE_VERSION} \
	ninja==${NINJA_VERSION} \
	trl==${TRL_VERSION} \
	peft==${PEFT_VERSION} \
	flash-attn==${FLASH_ATTN_VERSION}

# hf_transfer will be a built-in feature, remove the env variavle then
ENV HF_HUB_ENABLE_HF_TRANSFER="1"

RUN apt-get update \
 # TODO: Remove upgrade statements once packages are updated in base image
 && apt-get -y upgrade --only-upgrade systemd openssl cryptsetup libkrb5-3 linux-libc-dev \
 && apt install -y git git-lfs \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*


RUN apt-get remove -y --purge emacs emacs-common && \
apt-get autoremove -y

RUN HOME_DIR=/root \
 && curl -o ${HOME_DIR}/oss_compliance.zip https://aws-dlinfra-utilities.s3.amazonaws.com/oss_compliance.zip \
 && unzip -o ${HOME_DIR}/oss_compliance.zip -d ${HOME_DIR}/ \
 && cp ${HOME_DIR}/oss_compliance/test/testOSSCompliance /usr/local/bin/testOSSCompliance \
 && chmod +x /usr/local/bin/testOSSCompliance \
 && chmod +x ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh \
 && ${HOME_DIR}/oss_compliance/generate_oss_compliance.sh ${HOME_DIR} ${PYTHON} \
 && rm -rf ${HOME_DIR}/oss_compliance*

