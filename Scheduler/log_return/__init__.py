import os
import boto3
import xml.etree.ElementTree as ET
import json


def log_locater(report_path):
    """
    Create message that contains info allowing user to locate the logs

    :return: <json> returned message to SQS for locating the log
    """
    codebuild_arn = os.getenv("CODEBUILD_BUILD_ARN")
    ticket_name = os.getenv("TICKET_KEY").split("/")[-1].split(".")[0]
    log_group_name = f"/aws/codebuild/{codebuild_arn.split(':')[-2]}"
    log_stream_name = codebuild_arn.split(":")[-1]

    with open(report_path) as xml_file:
        report_data = ET.parse(xml_file).getroot()
        report_data_in_string = ET.tostring(report_data).decode("utf-8")

    content = {
        "LOG_GROUP_NAME": log_group_name,
        "LOG_STREAM_NAME": log_stream_name,
        "TICKET_NAME": ticket_name,
        "XML_REPORT": report_data_in_string,
    }

    return json.dumps(content)


def send_log(report_path):
    """
    Sending log message to SQS

    :param report_path: path to the xml reports generated by pytest
    """
    log_sqs_url = os.getenv("RETURN_SQS_URL")
    sqs_client = boto3.client("sqs")
    log_location = log_locater(report_path)
    sqs_client.send_message(QueueUrl=log_sqs_url, MessageBody=log_location)
    print(f"Logs successfully sent to {log_sqs_url}")


def update_pool(status, instance_type, num_of_instances, job_type):
    """
    Update the S3 resource pool for usage of SageMaker resources.
    Naming convention of resource usage json: request ticket_name#num_of_instances-status.

    :param status: status of the test job, options: preparing/running/completed/runtimeError
    :param instance_type: ml.p3.8xlarge/ml.c4.4xlarge/ml.p2.8xlarge/ml.c4.8xlarge
    :param num_of_instances: number of instances required
    """
    s3_client = boto3.client("s3")
    codebuild_arn = os.getenv("CODEBUILD_BUILD_ARN")
    ticket_name = os.getenv("TICKET_KEY").split("/")[-1].split(".")[0]

    if status not in {"preparing", "running", "completed", "runtimeError"}:
        raise ValueError("Not a valid status. Test job status could be preparing, running, completed or runtimeError.")

    pool_ticket_content = {
        "REQUEST_TICKET_KEY": os.getenv("TICKET_KEY"),
        "STATUS": status,
        "INSTANCE_TYPE": instance_type,
        "EXECUTOR_ARN": codebuild_arn,
        "INSTANCES_NUM": num_of_instances,
    }

    # delete existing entries of the job, if present
    response = s3_client.list_objects(
        Bucket="dlc-test-tickets", MaxKeys=1, Prefix=f"resource_pool/{instance_type}-{job_type}/{ticket_name}"
    )
    if "Contents" in response:
        previous_entry = response["Contents"][0]
        s3_client.delete_object(Bucket="dlc-test-tickets", Key=previous_entry["Key"])

    # creating json file locally and upload to S3
    filename = f"{ticket_name}#{num_of_instances}-{status}.json"
    with open(filename, "w") as f:
        json.dump(pool_ticket_content, f)

    with open(filename, "rb") as data:
        s3_client.upload_fileobj(data, "dlc-test-tickets", f"resource_pool/{instance_type}-{job_type}/{filename}")
