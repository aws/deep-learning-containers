# AWS Deep Learning Containers for PyTorch 2.4 Training on SageMaker

[AWS Deep Learning Containers](https://aws.amazon.com/machine-learning/containers/) (DLCs) for Amazon SageMaker (SM) are now available with PyTorch
2.4 and support for CUDA 12.4 on Ubuntu 22.04.

This release includes container images for training on GPU, optimized for performance and scale on AWS. These Docker images have been tested with SM
service, and provide stable versions of NVIDIA CUDA, Intel MKL, and other components. All software components in these images are scanned for security
vulnerabilities and updated or patched in accordance with AWS Security best practices.

## Release Notes

- Introduced containers for PyTorch 2.4.0 for training which support SageMaker service. For details about this release, check out our GitHub
  [release tag](https://github.com/aws/deep-learning-containers/releases/tag/v1.0-pt-sagemaker-2.4.0-tr-py311).
- PyTorch 2.4 offers support for python custom operator API allowing users to integrate custom kernels such as Triton kernels into torch.compile.
- PyTorch 2.4 also offers AOTInductor freezing allowing for more AOTInductor optimizations. It also offers a new default TCPStore server backend
  utilizing libuv which should reduce initialization times for large-scale jobs.
- Please refer to the official PyTorch 2.4 release notes [here](https://github.com/pytorch/pytorch/releases/tag/v2.4.0) for the full description of
  updates.
- Added EC2 P5 instance support
- Added Python 3.11 support
- Added CUDA 12.4 support
- Added Ubuntu 22.04 support
- The GPU Docker Image includes the following libraries:
  - CUDA 12.4.1
  - cuDNN 9.1.0.70
  - NCCL 2.22.3
  - AWS OFI NCCL plugin 1.11.0
  - EFA installer 1.34.0
  - Transformer Engine 1.9
  - Flash Attention 2.4.2
  - GDRCopy 2.4.1
  - Apex 24.04.01
- The Dockerfile for CPU can be found
  [here](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/2.4/py3/Dockerfile.cpu), and the Dockerfile for GPU can
  be found [here](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/2.4/py3/cu124/Dockerfile.gpu).

For latest updates, please refer to the [aws/deep-learning-containers GitHub repo](https://github.com/aws/deep-learning-containers/tags).

## Security Advisory

AWS recommends that customers monitor critical security updates in the [AWS Security Bulletin](https://aws.amazon.com/security/security-bulletins/).

## Python 3.11 Support

Python 3.11 is supported in the PyTorch Training and Inference containers.

## CPU Instance Type Support

The containers support x86_64 instance types.

## GPU Instance Type Support

The containers support GPU instance types and contain the following software components for GPU support:

- CUDA 12.4.1
- cuDNN 9.1.0.70+cuda12.4
- NCCL 2.22.3+cuda12.4

## Build and Test

- Built on: c5.18xlarge
- Tested on: g3.16xlarge, p3.16xlarge, p3dn.24xlarge, p4d.24xlarge, p4de.24xlarge, g4dn.xlarge, p5.48xlarge
- Tested with Resnet50, BERT along with ImageNet datasets on EC2, ECS AMI (Amazon Linux AMI 2.0.20240515), and EKS AMI
  (amazon-eks-gpu-node-1.25.16-20240514)

## Known Issues

- Customers using [TransformerEngine](https://github.com/NVIDIA/TransformerEngine) may run into
  `[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())`
  due to [NVFuser deprecation](https://github.com/pytorch/pytorch/commit/e6b5e0ecc609c15bfee5b383fe5c55fbdfda68ff) since PyTorch 2.2. For more
  information, please check this [issue](https://github.com/NVIDIA/TransformerEngine/issues/666).
