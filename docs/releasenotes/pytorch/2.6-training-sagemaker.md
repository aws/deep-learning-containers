# AWS Deep Learning Containers for PyTorch 2.6 Training on SageMaker

[AWS Deep Learning Containers](https://aws.amazon.com/machine-learning/containers/) (DLCs) for Amazon SageMaker are now available with PyTorch 2.6 and support for CUDA 12.6 on Ubuntu 22.04.

## Release Notes

- Introduced containers for PyTorch 2.6.0 for training which support SageMaker service. For details about this release, check out our GitHub [release tag](https://github.com/aws/deep-learning-containers/releases/tag/v1.0-pt-sagemaker-2.6.0-tr-py312).
- Starting with PyTorch 2.6, we are removing Conda from the DLCs and installing all Python packages from PyPI.
- PyTorch 2.6 features multiple improvements for PT2: torch.compile can now be used with Python 3.13; new performance-related knob torch.compiler.set_stance; several AOTInductor enhancements. Besides the PT2 improvements, another highlight is FP16 support on X86 CPUs.
- Removed [fastai](https://github.com/fastai/fastai) since it hasn't released PyTorch 2.6 compatible version.
- Added Python 3.12, CUDA 12.6, Ubuntu 22.04 support
- The GPU Docker Image includes: CUDA 12.6.3, cuDNN 9.7.0.66, NCCL 2.23.4, EFA installer 1.38.0, Transformer Engine 2.0, Flash Attention 2.7.3, GDRCopy 2.5

## Security Advisory

AWS recommends that customers monitor critical security updates in the [AWS Security Bulletin](https://aws.amazon.com/security/security-bulletins/).

## GPU Instance Type Support

- CUDA 12.6.3
- cuDNN 9.7.0.66+cuda12.6
- NCCL 2.23.4+cuda12.6

## Known Issues

- Customers using [TransformerEngine](https://github.com/NVIDIA/TransformerEngine) may run into NVFuser deprecation warnings.
