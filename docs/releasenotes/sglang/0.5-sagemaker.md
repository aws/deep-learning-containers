# AWS Deep Learning Containers for SGLang with EFA Support on SageMaker

[AWS Deep Learning Containers (DLCs)](https://aws.amazon.com/machine-learning/containers/) now support SGLang images optimized for large language model serving on Amazon SageMaker. The SGLang DLC provides a production-ready environment for deploying and serving LLMs with advanced features like RadixAttention for efficient KV cache reuse and optimized batch scheduling.

## Changelog

To learn about latest changes in SGLang DLC, checkout the [changelog](https://github.com/aws/deep-learning-containers/blob/master/sglang/CHANGELOG.md).

A list of available containers can be found on [GitHub](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#sglang-containers).

SGLang v0.5.5 and above utilizes CUDA 12.9 which is only compatible with Nvidia Driver 535 and above (550 preferred). To deploy the container on SageMaker platform, please specify `al2-ami-sagemaker-inference-gpu-3-1` as the [ProductionVariant](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html).

For guide on how to use SGLang DLC on SageMaker, checkout [tutorial](https://docs.sglang.io/get_started/install.html#method-7-run-on-aws-sagemaker). For guide on how to use SGLang, checkout [SGLang documentation](https://docs.sglang.io/).

## Security Advisory

AWS recommends that customers monitor critical security updates in the [AWS Security Bulletin](https://aws.amazon.com/security/security-bulletins/).

## Python Support

Python 3.12 is supported.

## Instance Type Support

The containers support x86_64 instance types.

## Build and Test

- Built on: c5.18xlarge
- Tested on: p4d.24xlarge, p5.48xlarge
- Tested with Qwen/Qwen3-0.6B model, single-node and multi-node serving configurations

## Known Issues

No known issues so far.
